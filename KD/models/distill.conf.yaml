global:
  seed: 2023
  loss_alpha: 0.1
  optimizer: 'Adam'
  ground: False

# specific configurations of each model
GCN:
  num_layers: 2
  hidden: 32
  learning_rate: 0.01
  dropout: 0.8
  weight_decay: 0.001
  temp: 1.0
  att: False
  layer_flag: False
GAT:
  num_layers: 4
  hidden: 32
  learning_rate: 0.01
  dropout: 0.6
  att_dropout: 0.3
  alpha: 0.2
  weight_decay: 0.01
  temp: 1.0
  num_heads: 4
  att: True
  layer_flag: False
GraphSAGE:
  agg_type: 'gcn'   # mean/gcn/pool/lstm
  embed_dim: 64
  batch_size: 256
  num_samples: 5
  learning_rate: 0.01
  weight_decay: 0.0005
#  optimizer: 'SGD'
  att: False
  layer_flag: False
GCNII:
  learning_rate: 0.01
  wd1: 0.01
  wd2: 0.0005
  layer: 8
  hidden: 32
  dropout: 0.6
  alpha: 0.1
  lamda: 0.5
PLP:
  num_layers: 10
  reduced_dim: 64
  learning_rate: 0.01
  dropout: 0.8
  weight_decay: 0.01
  temp: 1.0
  coefficient_dropout: 0.1
  att_dropout: 0.3
  lr_ratio: 0 # Weight of linear regression
  beta: 0
  att: True
  layer_flag: False